{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AcRi-HtfDaJ",
        "outputId": "d60abb6b-4cc2-4303-9291-6348cd593b54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PR0MYbDfGrG"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "pd.set_option('display.max_columns', None) # so it prints all the dataframe columns ...\n",
        "\n",
        "!pip install demjson3\n",
        "from demjson3 import decode\n",
        "import json\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import time\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2HWJB7aXVD3",
        "outputId": "f5cb502e-08fa-439e-a533-97c82562b144"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All 119 rows of \"/content/drive/MyDrive/Feature_extraction_results/finished_new_prompt_CD012768_hard.csv\" were added to \"csv_df\" .. \n",
            "\"csv_df\" has 119 rows after duplicate removal ...\n",
            "===========\n",
            "All 119 rows of \"/content/drive/MyDrive/Feature_extraction_results/ada_embed_CD012768.csv\" were added to \"csv_df\" .. \n",
            "\"csv_df\" has 238 rows after duplicate removal ...\n",
            "===========\n",
            "All 119 rows of \"/content/drive/MyDrive/Feature_extraction_results/finished_new_prompt_CD012768_soft.csv\" were added to \"csv_df\" .. \n",
            "\"csv_df\" has 357 rows after duplicate removal ...\n",
            "===========\n",
            "All 119 rows of \"/content/drive/MyDrive/Feature_extraction_results/finished_new_prompt_CD012768.csv\" were added to \"csv_df\" .. \n",
            "\"csv_df\" has 476 rows after duplicate removal ...\n",
            "===========\n",
            "All 1799 rows of \"/content/drive/MyDrive/Feature_extraction_results/ada_embed_CD008874.csv\" were added to \"csv_df\" .. \n",
            "\"csv_df\" has 2275 rows after duplicate removal ...\n",
            "===========\n",
            "All 1799 rows of \"/content/drive/MyDrive/Feature_extraction_results/finished_new_prompt_CD008874.csv\" were added to \"csv_df\" .. \n",
            "\"csv_df\" has 4074 rows after duplicate removal ...\n",
            "===========\n",
            "All 1799 rows of \"/content/drive/MyDrive/Feature_extraction_results/finished_new_prompt_CD008874_soft.csv\" were added to \"csv_df\" .. \n",
            "\"csv_df\" has 5873 rows after duplicate removal ...\n",
            "===========\n",
            "All 3120 rows of \"/content/drive/MyDrive/Feature_extraction_results/ada_embed_CD009044.csv\" were added to \"csv_df\" .. \n",
            "\"csv_df\" has 8993 rows after duplicate removal ...\n",
            "===========\n",
            "All 3120 rows of \"/content/drive/MyDrive/Feature_extraction_results/finished_new_prompt_CD009044.csv\" were added to \"csv_df\" .. \n",
            "\"csv_df\" has 12113 rows after duplicate removal ...\n",
            "===========\n",
            "All 3120 rows of \"/content/drive/MyDrive/Feature_extraction_results/finished_new_prompt_CD009044_hard.csv\" were added to \"csv_df\" .. \n",
            "\"csv_df\" has 15233 rows after duplicate removal ...\n",
            "===========\n",
            "All 3120 rows of \"/content/drive/MyDrive/Feature_extraction_results/finished_new_prompt_CD009044_soft.csv\" were added to \"csv_df\" .. \n",
            "\"csv_df\" has 18353 rows after duplicate removal ...\n",
            "===========\n",
            "All 8032 rows of \"/content/drive/MyDrive/Feature_extraction_results/ada_embed_CD011686.csv\" were added to \"csv_df\" .. \n",
            "\"csv_df\" has 26385 rows after duplicate removal ...\n",
            "===========\n",
            "All 8032 rows of \"/content/drive/MyDrive/Feature_extraction_results/finished_new_prompt_CD011686.csv\" were added to \"csv_df\" .. \n",
            "\"csv_df\" has 34417 rows after duplicate removal ...\n",
            "===========\n",
            "All 8032 rows of \"/content/drive/MyDrive/Feature_extraction_results/finished_new_prompt_CD011686_hard.csv\" were added to \"csv_df\" .. \n",
            "\"csv_df\" has 42449 rows after duplicate removal ...\n",
            "===========\n",
            "All 8032 rows of \"/content/drive/MyDrive/Feature_extraction_results/finished_new_prompt_CD011686_soft.csv\" were added to \"csv_df\" .. \n",
            "\"csv_df\" has 50481 rows after duplicate removal ...\n",
            "===========\n",
            "All 6314 rows of \"/content/drive/MyDrive/Feature_extraction_results/ada_embed_CD012080.csv\" were added to \"csv_df\" .. \n",
            "\"csv_df\" has 56795 rows after duplicate removal ...\n",
            "===========\n",
            "All 6314 rows of \"/content/drive/MyDrive/Feature_extraction_results/finished_new_prompt_CD012080.csv\" were added to \"csv_df\" .. \n",
            "\"csv_df\" has 63109 rows after duplicate removal ...\n",
            "===========\n",
            "All 6314 rows of \"/content/drive/MyDrive/Feature_extraction_results/finished_new_prompt_CD012080_hard.csv\" were added to \"csv_df\" .. \n",
            "\"csv_df\" has 69423 rows after duplicate removal ...\n",
            "===========\n",
            "All 6314 rows of \"/content/drive/MyDrive/Feature_extraction_results/finished_new_prompt_CD012080_soft.csv\" were added to \"csv_df\" .. \n",
            "\"csv_df\" has 75737 rows after duplicate removal ...\n",
            "===========\n",
            "All 430 rows of \"/content/drive/MyDrive/Feature_extraction_results/finished_new_prompt_CD012233_soft.csv\" were added to \"csv_df\" .. \n",
            "\"csv_df\" has 76167 rows after duplicate removal ...\n",
            "===========\n",
            "All 430 rows of \"/content/drive/MyDrive/Feature_extraction_results/finished_new_prompt_CD012233.csv\" were added to \"csv_df\" .. \n",
            "\"csv_df\" has 76597 rows after duplicate removal ...\n",
            "===========\n",
            "All 430 rows of \"/content/drive/MyDrive/Feature_extraction_results/ada_embed_CD012233.csv\" were added to \"csv_df\" .. \n",
            "\"csv_df\" has 77027 rows after duplicate removal ...\n",
            "===========\n",
            "All 430 rows of \"/content/drive/MyDrive/Feature_extraction_results/finished_new_prompt_CD012233_hard.csv\" were added to \"csv_df\" .. \n",
            "\"csv_df\" has 77457 rows after duplicate removal ...\n",
            "===========\n",
            "All 5863 rows of \"/content/drive/MyDrive/Feature_extraction_results/ada_embed_CD012567.csv\" were added to \"csv_df\" .. \n",
            "\"csv_df\" has 83320 rows after duplicate removal ...\n",
            "===========\n",
            "All 5863 rows of \"/content/drive/MyDrive/Feature_extraction_results/finished_new_prompt_CD012567.csv\" were added to \"csv_df\" .. \n",
            "\"csv_df\" has 89183 rows after duplicate removal ...\n",
            "===========\n",
            "All 5863 rows of \"/content/drive/MyDrive/Feature_extraction_results/finished_new_prompt_CD012567_hard.csv\" were added to \"csv_df\" .. \n",
            "\"csv_df\" has 95046 rows after duplicate removal ...\n",
            "===========\n",
            "All 5863 rows of \"/content/drive/MyDrive/Feature_extraction_results/finished_new_prompt_CD012567_soft.csv\" were added to \"csv_df\" .. \n",
            "\"csv_df\" has 100909 rows after duplicate removal ...\n",
            "===========\n",
            "All 1153 rows of \"/content/drive/MyDrive/Feature_extraction_results/ada_embed_CD012669.csv\" were added to \"csv_df\" .. \n",
            "\"csv_df\" has 102062 rows after duplicate removal ...\n",
            "===========\n",
            "All 1153 rows of \"/content/drive/MyDrive/Feature_extraction_results/finished_new_prompt_CD012669.csv\" were added to \"csv_df\" .. \n",
            "\"csv_df\" has 103215 rows after duplicate removal ...\n",
            "===========\n",
            "All 1153 rows of \"/content/drive/MyDrive/Feature_extraction_results/finished_new_prompt_CD012669_hard.csv\" were added to \"csv_df\" .. \n",
            "\"csv_df\" has 104368 rows after duplicate removal ...\n",
            "===========\n",
            "All 1153 rows of \"/content/drive/MyDrive/Feature_extraction_results/finished_new_prompt_CD012669_soft.csv\" were added to \"csv_df\" .. \n",
            "\"csv_df\" has 105521 rows after duplicate removal ...\n",
            "===========\n",
            "Total count of of \"PMID\" values:\t105521\n",
            "Duplicate count of \"PMID\" column:\t78714\n",
            "Number of distinct \"PMID\" values:\t26807\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "import glob\n",
        "csv_df = pd.DataFrame(columns=[])\n",
        "# for file in glob.glob(\"/content/drive/MyDrive/changed_CD012768*.csv\"): # tested the whole thing only on \"changed_CD012768.csv\" and \"changed_CD012768 (copy).csv\" ...\n",
        "for file in glob.glob(\"/content/drive/MyDrive/Feature_extraction_results/*.csv\"):\n",
        "  filename = os.path.basename(file)\n",
        "  temp_df = pd.read_csv(file, index_col=0)\n",
        "  temp_df[ \"Filename\" ]=filename\n",
        "  if ( \"'int'\" in str(type(csv_df)) ):\n",
        "    csv_df = temp_df.copy()\n",
        "  else:\n",
        "    csv_df = pd.concat([csv_df, temp_df], axis=0, ignore_index=True)\n",
        "  print( \"All \" + str(temp_df.shape[0]) + \" rows of \\\"\" + file + \"\\\" were added to \\\"csv_df\\\" .. \" )\n",
        "  # print( \"\\\"csv_df\\\" has \" + str(csv_df.shape[0]) + \" rows ...\" )\n",
        "  # csv_df = csv_df.drop_duplicates()\n",
        "  print( \"\\\"csv_df\\\" has \" + str(csv_df.shape[0]) + \" rows after duplicate removal ...\" )\n",
        "  print( \"===========\" )\n",
        "\n",
        "print( \"Total count of of \\\"PMID\\\" values:\\t\" + str(csv_df.shape[0]) )\n",
        "print( \"Duplicate count of \\\"PMID\\\" column:\\t\" + str(csv_df.duplicated(subset=\"PMID\").sum()) )\n",
        "\n",
        "pmids = list(csv_df[\"PMID\"])\n",
        "pmids = list(dict.fromkeys(pmids)) # remove duplicate PMID values\n",
        "print( \"Number of distinct \\\"PMID\\\" values:\\t\" + str(len(pmids)) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmmNYxZmDwJs",
        "outputId": "be09b391-7fa5-47bf-d250-6378e2edd658"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['abstract', 'authors', 'chemicals', 'citation', 'doi', 'history',\n",
              "       'issn', 'issue', 'journal', 'keywords', 'mesh', 'pmc', 'pmid',\n",
              "       'publication_types', 'title', 'url', 'volume', 'volume_issue', 'xml',\n",
              "       'year', 'author_first', 'references', 'issn_data'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/checkpoint_12_df.csv\")\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMVnIpZk5M3R"
      },
      "outputs": [],
      "source": [
        "# this converts checkpoint_11 to checkpoint_12\n",
        "\n",
        "import requests\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def get_title(row):\n",
        "  try:\n",
        "    references_json = decode(row[\"references\"])\n",
        "    new_ref=[]\n",
        "    for ref in references_json:\n",
        "      # clear_output(wait=True)\n",
        "      # print( ref )\n",
        "      title = ref[\"citation\"]\n",
        "      arr = title.split()\n",
        "      if ( len(arr) == 1 ):\n",
        "        clear_output(wait=True)\n",
        "        print( row[\"references\"] )\n",
        "        print(title)\n",
        "        response = requests.get(f'https://api.openalex.org/works/doi:{title}')\n",
        "        decoded_json = decode(response.text)\n",
        "        authors = \"\"\n",
        "        for author in decoded_json[\"authorships\"]:\n",
        "          authors = authors + author[\"raw_author_name\"] + \", \"\n",
        "        authors = authors[:-2]\n",
        "        new_cit = authors + \" (\" + str(decoded_json[\"publication_year\"]) + \") \" + decoded_json[\"title\"] + \" \" + title\n",
        "        new_json = {}\n",
        "        new_json[\"citation\"] = new_cit\n",
        "        new_json[\"doi\"] = title\n",
        "        new_ref.append(new_json)\n",
        "      else:\n",
        "        new_ref.append(ref)\n",
        "    return json.dumps(new_ref)\n",
        "\n",
        "  except:\n",
        "    return row[\"references\"] # only gets here if \"Page Not Found\"\n",
        "\n",
        "# ref_arr = csv_df[csv_df[\"Filename\"] == \"finished_new_prompt_CD012768_soft.csv\"].apply( get_title, axis=1 )\n",
        "# df = pd.read_csv(\"/content/drive/MyDrive/checkpoint_11_df.csv\")\n",
        "df = df.astype(str)\n",
        "df[\"references\"] = df.apply( get_title, axis=1 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LrgCdDlEDP-"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"/content/drive/MyDrive/checkpoint_12_df.csv\", encoding='utf-8', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kz-qQTedXqlD"
      },
      "outputs": [],
      "source": [
        "csv_df = csv_df.astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GM89OaY3YRxJ",
        "outputId": "2d14dc9c-0979-46d8-b3ec-38a6c987c475"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 254 postive articles with no references and 22806 negative articles with no references.\n"
          ]
        }
      ],
      "source": [
        "no_ref_positive = csv_df[ (csv_df[\"references\"] == \"[]\") & (csv_df[\"Status\"] == \"1\") ]\n",
        "no_ref_negative = csv_df[ (csv_df[\"references\"] == \"[]\") & (csv_df[\"Status\"] == \"0\") ]\n",
        "print(f'There are {len(no_ref_positive)} postive articles with no references and {len(no_ref_negative)} negative articles with no references.')\n",
        "# no_ref_positive[\"Filename\"].value_counts() # prints how many positive no ref per file\n",
        "# no_ref_negative[\"Filename\"].value_counts() # prints how many negative no ref per file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7_Ff8MtIVfW",
        "outputId": "17fb03f9-806b-4928-8e71-5ce4d2ce8635"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(105521, 56)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "csv_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_EyIMd5qj7z",
        "outputId": "90c6c494-a12a-44f1-8909-a6a861fc2d9b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Criteria Similarity', 'PMID', 'Review Criteria', 'Review Title',\n",
              "       'Status', 'Title', 'Topic', 'ada_embedding', 'author_first', 'authors',\n",
              "       'c_score', 'chemicals', 'citation', 'doi', 'f_score', 'hard1', 'hard2',\n",
              "       'hard3', 'hard4', 'hard5', 'history', 'issn', 'issn_data', 'issue',\n",
              "       'journal', 'keywords', 'mesh', 'pmc', 'prediction', 'publication_types',\n",
              "       'query1', 'query2', 'query3', 'query4', 'query5', 'question1',\n",
              "       'question2', 'question3', 'question4', 'question5', 'rank',\n",
              "       'references', 'score', 'soft1', 'soft2', 'soft3', 'soft4', 'soft5',\n",
              "       'text', 'url', 'vector1', 'volume', 'volume_issue', 'xml', 'year',\n",
              "       'Filename'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "csv_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6roCveNOAba"
      },
      "outputs": [],
      "source": [
        "csv_df_copy = csv_df.copy(deep=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZZ2EZrCOIkO"
      },
      "outputs": [],
      "source": [
        "csv_df = csv_df_copy.copy(deep=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "VGEjSf8KOX47",
        "outputId": "02d811b0-d49b-47db-c905-7f3a6c3b8f7f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>references</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>105521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>20943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>23091</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ],
            "text/plain": [
              "count     105521\n",
              "unique     20943\n",
              "top           []\n",
              "freq       23091\n",
              "Name: references, dtype: object"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "csv_df[\"references\"].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPSGejWS3i1Q",
        "outputId": "4548b8d7-0278-4eed-ca7f-c0d46d8f1b71"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['finished_new_prompt_CD012768_soft.csv',\n",
              "       'finished_new_prompt_CD012768_hard.csv', 'ada_embed_CD012768.csv',\n",
              "       'finished_new_prompt_CD012768.csv', 'ada_embed_CD008874.csv',\n",
              "       'finished_new_prompt_CD008874.csv',\n",
              "       'finished_new_prompt_CD008874_soft.csv', 'ada_embed_CD009044.csv',\n",
              "       'finished_new_prompt_CD009044.csv',\n",
              "       'finished_new_prompt_CD009044_hard.csv',\n",
              "       'finished_new_prompt_CD009044_soft.csv', 'ada_embed_CD011686.csv',\n",
              "       'finished_new_prompt_CD011686.csv',\n",
              "       'finished_new_prompt_CD011686_hard.csv',\n",
              "       'finished_new_prompt_CD011686_soft.csv', 'ada_embed_CD012080.csv',\n",
              "       'finished_new_prompt_CD012080.csv',\n",
              "       'finished_new_prompt_CD012080_hard.csv',\n",
              "       'finished_new_prompt_CD012080_soft.csv',\n",
              "       'finished_new_prompt_CD012233_soft.csv',\n",
              "       'finished_new_prompt_CD012233.csv',\n",
              "       'finished_new_prompt_CD012233_hard.csv', 'ada_embed_CD012233.csv',\n",
              "       'ada_embed_CD012567.csv', 'finished_new_prompt_CD012567.csv',\n",
              "       'finished_new_prompt_CD012567_hard.csv',\n",
              "       'finished_new_prompt_CD012567_soft.csv', 'ada_embed_CD012669.csv',\n",
              "       'finished_new_prompt_CD012669.csv',\n",
              "       'finished_new_prompt_CD012669_hard.csv',\n",
              "       'finished_new_prompt_CD012669_soft.csv'], dtype=object)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "csv_df[\"Filename\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "vRZi-4pR3CF1",
        "outputId": "4a9e6b19-bb56-48d6-ef35-186ce68cc1fe"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>references</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[{\"doi\": \"10.1164/ajrccm/148.5.1292\", \"citatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[{\"doi\": \"10.4103/0019-5413.93688\", \"citation\"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[{\"doi\": \"10.5.3.327\", \"citation\": \"Expert Rev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[{\"doi\": \"10.1128/CMR.00042-10\", \"citation\": \"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[{\"doi\": \"10.1016/j.tube.2013.04\", \"citation\":...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>[{\"citation\": \"WHO  Health Topics: Meningitis....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>[{\"doi\": \"10.2217/fmb.11\", \"citation\": \"Future...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>[{\"citation\": \"Geneva, Switzerland: World Heal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>[{\"doi\": \"10.1128/JCM.00491-11\", \"citation\": \"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>[{\"doi\": \"10.1097/MCP.0b013e32835f4fe4\", \"cita...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>106 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ],
            "text/plain": [
              "0      [{\"doi\": \"10.1164/ajrccm/148.5.1292\", \"citatio...\n",
              "1      [{\"doi\": \"10.4103/0019-5413.93688\", \"citation\"...\n",
              "2      [{\"doi\": \"10.5.3.327\", \"citation\": \"Expert Rev...\n",
              "4      [{\"doi\": \"10.1128/CMR.00042-10\", \"citation\": \"...\n",
              "5      [{\"doi\": \"10.1016/j.tube.2013.04\", \"citation\":...\n",
              "                             ...                        \n",
              "112    [{\"citation\": \"WHO  Health Topics: Meningitis....\n",
              "113    [{\"doi\": \"10.2217/fmb.11\", \"citation\": \"Future...\n",
              "114    [{\"citation\": \"Geneva, Switzerland: World Heal...\n",
              "115    [{\"doi\": \"10.1128/JCM.00491-11\", \"citation\": \"...\n",
              "116    [{\"doi\": \"10.1097/MCP.0b013e32835f4fe4\", \"cita...\n",
              "Name: references, Length: 106, dtype: object"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "csv_df[csv_df[\"Filename\"] == \"finished_new_prompt_CD012768_soft.csv\"][\"references\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFnaf43JibgT",
        "outputId": "6b76dcaa-d7f7-49d4-eabf-083e742cac77"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(105521, 56)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "csv_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7ukdmObflRz"
      },
      "outputs": [],
      "source": [
        "def get_empty(row):\n",
        "  if ( row[\"references\"] == \"[]\" ):\n",
        "    return row[\"PMID\"]\n",
        "  if ( str(row[\"references\"]) == \"nan\" ):\n",
        "    return row[\"PMID\"]\n",
        "  return \"\"\n",
        "\n",
        "empty_row_iter = csv_df.apply( get_empty, axis=1 )\n",
        "empty_row_iter = [x for x in empty_row_iter if x != \"\"]\n",
        "csv_df = csv_df[~csv_df[\"PMID\"].isin(empty_row_iter) ] # here ~ is equivalent to NOT (negates the statement)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pLzznb7IEdb",
        "outputId": "ccf55338-df1a-4f0a-bf26-81cbbba18510"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(82426, 56)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "csv_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHrLLxQpOOuL",
        "outputId": "135b9983-264f-498f-c926-7b0e0e56f35c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "23095"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(empty_row_iter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFmTLL0BU3PY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd80358c-1479-44ce-8c05-0a92262562d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: demjson3 in /usr/local/lib/python3.11/dist-packages (3.0.6)\n",
            "temp: (106, 56)\n",
            "temp: (106, 56)\n",
            "temp: (106, 56)\n",
            "temp: (106, 56)\n",
            "temp: (1450, 56)\n",
            "temp: (1450, 56)\n",
            "temp: (1450, 56)\n",
            "temp: (3014, 56)\n",
            "temp: (3014, 56)\n",
            "temp: (3014, 56)\n",
            "temp: (3014, 56)\n",
            "temp: (5974, 56)\n",
            "temp: (5974, 56)\n",
            "temp: (5974, 56)\n",
            "temp: (5974, 56)\n",
            "temp: (5008, 56)\n",
            "temp: (5008, 56)\n",
            "temp: (5008, 56)\n",
            "temp: (5008, 56)\n",
            "temp: (282, 56)\n",
            "temp: (282, 56)\n",
            "temp: (282, 56)\n",
            "temp: (282, 56)\n",
            "temp: (4148, 56)\n",
            "temp: (4148, 56)\n",
            "temp: (4148, 56)\n",
            "temp: (4148, 56)\n",
            "temp: (987, 56)\n",
            "temp: (987, 56)\n",
            "temp: (987, 56)\n",
            "temp: (987, 56)\n"
          ]
        }
      ],
      "source": [
        "# you might have the same reference formulated differently amongst more rows ...\n",
        "# since there are references that have no unique identifier (doi/pmid) maybe it would be best\n",
        "# if i did an NLP comparison between em to see if they are the same ...\n",
        "# this would then be a citation network that is based on citation SIMMILARITY not identicality which might NOT have been done yet ...\n",
        "# !pip install fix-busted-json\n",
        "# from fix_busted_json import repair_json\n",
        "\n",
        "import json\n",
        "!pip install demjson3\n",
        "from demjson3 import decode\n",
        "from IPython.display import clear_output\n",
        "\n",
        "missed = []\n",
        "def get_json_citation(row):\n",
        "  global missed\n",
        "  succeeded = True\n",
        "\n",
        "  try:\n",
        "    references_json = decode(row[\"references\"])\n",
        "    citations=[]\n",
        "    for ref in references_json:\n",
        "      # clear_output(wait=True)\n",
        "      # print( ref )\n",
        "      citations.append( ref[\"citation\"] )\n",
        "    return json.dumps(citations)\n",
        "  except:\n",
        "    missed.append( row[\"references\"] )\n",
        "\n",
        "# if ( not succeeded ):\n",
        "#   try:\n",
        "#     missed.append( row[\"references\"] )\n",
        "#     references_json = repair_json(row[\"references\"])\n",
        "#     citations=[]\n",
        "#     for ref in references_json:\n",
        "#       clear_output(wait=True)\n",
        "#       print( ref )\n",
        "#       citations.append( ref[\"citation\"] )\n",
        "#     return json.dumps(citations)\n",
        "#   except:\n",
        "#     missed.append( row[\"references\"] )\n",
        "#     clear_output(wait=True)\n",
        "#     print(len(missed))\n",
        "#     return \"[]\"\n",
        "\n",
        "# print(missed)\n",
        "\n",
        "filenames = csv_df[\"Filename\"].unique().tolist()\n",
        "cit_dfs = []\n",
        "all_citations = []\n",
        "for filename in filenames:\n",
        "  temp_df = csv_df[ csv_df[\"Filename\"] == filename ].copy(deep=True)\n",
        "  print( f'temp: {temp_df.shape}' )\n",
        "  temp_df[\"reference_array\"] = temp_df.apply( get_json_citation, axis=1 )\n",
        "  all_citations.extend( temp_df[\"reference_array\"].tolist() )\n",
        "  file_df = temp_df[[\"PMID\", \"citation\", \"reference_array\", \"Status\"]]\n",
        "  cit_dfs.append(file_df)\n",
        "\n",
        "# print(cit_dfs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HYRF0L4VhpO"
      },
      "outputs": [],
      "source": [
        "csv_df_copy_1 = csv_df.copy(deep=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CX9eBOtVXWMV"
      },
      "outputs": [],
      "source": [
        "cit_dfs_copy = []\n",
        "\n",
        "for i in range(0, len(cit_dfs)):\n",
        "  cit_dfs_copy.append(cit_dfs[i].copy(deep=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_wX_HvOkUeF"
      },
      "outputs": [],
      "source": [
        "cit_dfs = []\n",
        "\n",
        "for i in range(0, len(cit_dfs_copy)):\n",
        "  cit_dfs.append(cit_dfs_copy[i].copy(deep=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGMxy-lvyS4-"
      },
      "outputs": [],
      "source": [
        "cit_dfs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_O3SAkA2XAc"
      },
      "outputs": [],
      "source": [
        "cit_dfs[0][cit_dfs[0][\"Status\"] == \"1\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4iOUHZv5ixJ"
      },
      "outputs": [],
      "source": [
        "cit_dfs0 = cit_dfs[0].copy(deep=True)\n",
        "cit_dfs0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iK8E8cmb8Q_U"
      },
      "outputs": [],
      "source": [
        "cit_dfs[0] = cit_dfs_copy[0].copy(deep=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiOkrSWmLoNr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c301d4b1-7706-4d28-846b-86fb03c3615f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.039212891527794676"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "import nltk, string\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "nltk.download('punkt') # if necessary...\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "stemmer = nltk.stem.porter.PorterStemmer()\n",
        "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
        "\n",
        "def stem_tokens(tokens):\n",
        "    return [stemmer.stem(item) for item in tokens]\n",
        "\n",
        "'''remove punctuation, lowercase, stem'''\n",
        "def normalize(text):\n",
        "    return stem_tokens(nltk.word_tokenize(text.lower().translate(remove_punctuation_map)))\n",
        "\n",
        "vectorizer = TfidfVectorizer(tokenizer=normalize, stop_words='english')\n",
        "\n",
        "def cosine_sim(text1, text2):\n",
        "    tfidf = vectorizer.fit_transform([text1, text2])\n",
        "    # print( tfidf )\n",
        "    # return ((tfidf * tfidf.T).A)[0,1]\n",
        "    return ((tfidf * tfidf.T))[0,1]\n",
        "\n",
        "\n",
        "cosine_sim('PLoS One Claassens 8 e76272 2013 10.1371/journal.pone.0076272 Tuberculosis in healthcare workers and infection control measures at primary healthcare facilities in South Africa', 'van Soolingen D, Hermans PW, de Haas PE, Soll DR, van Embden JD. Occurrence and stability of insertion sequences in Mycobacterium tuberculosis complex strains: evaluation of an insertion sequence-dependent DNA polymorphism as a tool in the epidemiology of tuberculosis. Journal of clinical microbiology. 1991;29(11):2578–86.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUDqPmeBKinW",
        "outputId": "45448a26-6342-4c60-ab07-66a13166d60c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(cit_dfs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "VeZs4AoqpsEm",
        "outputId": "dd9f45e6-1d45-4d54-85ee-0c8af8262575"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>citation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Peter JG, et al. The diagnostic accuracy of ur...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Held M, et al. Diagnostic Accuracy of the Xper...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Chang K, et al. Rapid and effective diagnosis ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Patel VB, et al. Diagnostic accuracy of quanti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Hodkinson B, et al. HIV Infection and Osteoart...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>Rajasingham R, et al. Epidemiology of meningit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>Lawn SD and Zumla AI. Diagnosis of extrapulmon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>Du J, et al. Rapid diagnosis of pleural tuberc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>Marouane C, et al. Evaluation of molecular det...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>Bates M, et al. Burden of tuberculosis at post...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>106 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ],
            "text/plain": [
              "0      Peter JG, et al. The diagnostic accuracy of ur...\n",
              "1      Held M, et al. Diagnostic Accuracy of the Xper...\n",
              "2      Chang K, et al. Rapid and effective diagnosis ...\n",
              "4      Patel VB, et al. Diagnostic accuracy of quanti...\n",
              "5      Hodkinson B, et al. HIV Infection and Osteoart...\n",
              "                             ...                        \n",
              "112    Rajasingham R, et al. Epidemiology of meningit...\n",
              "113    Lawn SD and Zumla AI. Diagnosis of extrapulmon...\n",
              "114    Du J, et al. Rapid diagnosis of pleural tuberc...\n",
              "115    Marouane C, et al. Evaluation of molecular det...\n",
              "116    Bates M, et al. Burden of tuberculosis at post...\n",
              "Name: citation, Length: 106, dtype: object"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cit_dfs[0][\"citation\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TZIx9LHkC8m"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "directory=\"/content/drive/MyDrive/Citation_dataframes\"\n",
        "if not os.path.exists(directory):\n",
        "    os.makedirs(directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnF1pnH8KMA2",
        "outputId": "99789363-85e5-4156-fb09-69f79bc1a066"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computed row 2776 / 3014.\n",
            "Skipped 3818422252 citations, applied cosine simmilarity to 210104 citations so far ... \n"
          ]
        }
      ],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "all_refs = []\n",
        "\n",
        "def ensure_positive(a):\n",
        "  if ( a < 0 ):\n",
        "    return -a\n",
        "  else:\n",
        "    return a\n",
        "\n",
        "def tokenise_citation(cit):\n",
        "  global stop_words\n",
        "  tokenizer = RegexpTokenizer(r'\\w+') # tokenises after removing punctuation marks\n",
        "  word_tokens = tokenizer.tokenize(cit)\n",
        "  filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words] # remove stopwords\n",
        "  return filtered_sentence\n",
        "\n",
        "def get_common_citation_word_count(cit1, cit2):\n",
        "  cit1_tokens = tokenise_citation(cit1)\n",
        "  cit2_tokens = tokenise_citation(cit2)\n",
        "  # cit1_tokens = [\"0\", \"7\", \"6\", \"5\", \"4\", \"3\", \"2\"]\n",
        "  # cit2_tokens = [\"1\", \"2\", \"9\", \"8\", \"7\", \"6\", \"5\"]\n",
        "  # common_tokens = list(set(cit1_tokens) & set(cit2_tokens))\n",
        "  # common_tokens # outputs ['7', '5', '2', '6'], it's ok\n",
        "  common_tokens = list(set(cit1_tokens) & set(cit2_tokens)) # this compares unique words, each \"set\" contains NO duplicate words ...\n",
        "  return len(common_tokens)\n",
        "\n",
        "def check_if_viable_for_cosine_sim(cit, is_positive=False):\n",
        "  global all_refs\n",
        "  global skipped\n",
        "  global applied\n",
        "  global df_rows\n",
        "  global row_iter\n",
        "  global cit_iter\n",
        "  global average_citation_count\n",
        "  global df_cit_iter\n",
        "  should_cosine=False\n",
        "\n",
        "  iter=0\n",
        "  refs_length = len(all_refs)\n",
        "  arr=[]\n",
        "  skip_count = 0\n",
        "\n",
        "  start_iter = -1\n",
        "  end_iter = -1\n",
        "\n",
        "  if ( is_positive == False ):\n",
        "    if ( df_rows <= 1500 ):\n",
        "      for i in range(0, refs_length):\n",
        "        if ( round(len(cit)/len(all_refs[i]), 3) <= 1.000 ): # if it's < 1.00 is almost right, but it cuts some rows ...\n",
        "          if ( start_iter == -1 ):\n",
        "            start_iter = i\n",
        "            continue\n",
        "        if ( round(len(cit)/len(all_refs[i]), 3) <= 0.995 ):\n",
        "          if ( end_iter == -1 ):\n",
        "            end_iter = i + 1\n",
        "            break\n",
        "\n",
        "    if ( df_rows >= 1500 ):\n",
        "      for i in range(0, refs_length):\n",
        "        if ( round(len(cit)/len(all_refs[i]), 8) <= 1.00000000 ): # if it's < 1.00 is almost right, but it cuts some rows ...\n",
        "          if ( start_iter == -1 ):\n",
        "            start_iter = i\n",
        "            continue\n",
        "        if ( round(len(cit)/len(all_refs[i]), 8) <= 0.99999995 ):\n",
        "          if ( end_iter == -1 ):\n",
        "            end_iter = i + 1\n",
        "            break\n",
        "\n",
        "    skip_count = refs_length - end_iter + start_iter\n",
        "    cit_num = end_iter - start_iter + 1\n",
        "  else:\n",
        "    start_iter = 0\n",
        "    end_iter = refs_length\n",
        "    cit_num = refs_length\n",
        "\n",
        "\n",
        "  for i in range(start_iter, end_iter):\n",
        "    if ( len(arr) == int(average_citation_count) and is_positive == True ):\n",
        "      break;\n",
        "\n",
        "    if ( all_refs[i] == cit ): # there won't be any (or nearly enough) if you search them to be identical ...\n",
        "      skip_count = skip_count + 1\n",
        "      continue\n",
        "\n",
        "    # if ( ensure_positive( len(cit) - len(u) ) > 10 ):\n",
        "    #   # print(ensure_positive( len(cit) - len(u) ))\n",
        "    #   skip_count = skip_count + 1\n",
        "    #   continue\n",
        "\n",
        "    wordcount = get_common_citation_word_count( cit, all_refs[i] )\n",
        "    # iter = iter + 1\n",
        "    # print( f'Going though ref {iter} / {refs_length} ...' )\n",
        "    treshold = 5\n",
        "    if ( df_rows >= 1500 ):\n",
        "      treshold = 7\n",
        "    if ( df_rows >= 5000 ):\n",
        "      treshold = 10\n",
        "    if ( wordcount >= treshold ): # adjust the treshold here ...\n",
        "      clear_output(wait=True)\n",
        "      arr.append(all_refs[i])\n",
        "      print(f'Computing row {row_iter} / {df_rows}: comparing citation {cit_iter} with citation {i - start_iter + 1} / {cit_num} (out of {refs_length} citations of the current df) ... \\nstart_iter={start_iter} end_iter={end_iter}\\nApplying cosine simmilarity wordcount={wordcount} ... \\nDid this for {applied} citations so far ... skipped {skipped} citations so far ... ')\n",
        "      applied = applied + 1\n",
        "      # time.sleep(1)\n",
        "      # should_cosine=True\n",
        "      # break\n",
        "    else:\n",
        "      skip_count = skip_count + 1\n",
        "\n",
        "  if ( len(arr) == 0 and is_positive == True ):\n",
        "    # print( 1 + \"1\" )\n",
        "    for i in range(0, refs_length):\n",
        "      if ( ensure_positive( len(cit) - len(all_refs[i]) ) < 2 ):\n",
        "        if ( start_iter == -1 ):\n",
        "          start_iter = i\n",
        "      if ( ensure_positive( len(cit) - len(all_refs[i]) ) > 10 ):\n",
        "        if ( end_iter == -1 ):\n",
        "          end_iter = i + 1\n",
        "          break\n",
        "    skip_count = refs_length - end_iter + start_iter\n",
        "    cit_num = end_iter - start_iter + 1\n",
        "\n",
        "    for i in range(start_iter, end_iter):\n",
        "      if ( i > int(average_citation_count) ):\n",
        "        break;\n",
        "      arr.append(all_refs[i])\n",
        "\n",
        "  if ( len(arr) == 0 and is_positive == True ):\n",
        "    print( 1 + \"1\" )\n",
        "    import random\n",
        "    for i in range(0, int(average_citation_count)):\n",
        "      rand = random.choice(all_refs)\n",
        "      if ( rand in arr ):\n",
        "        i = i - 1\n",
        "        continue\n",
        "      arr.append(all_refs[i])\n",
        "\n",
        "  # if ( len(arr) > average_citation_count ): # for maximum citation count\n",
        "  #   average_citation_count = len(arr)\n",
        "\n",
        "  average_citation_count = ( average_citation_count * df_cit_iter + len(arr) ) / ( df_cit_iter + 1 )\n",
        "  df_cit_iter = df_cit_iter + 1\n",
        "\n",
        "  if (len(arr)!=0):\n",
        "    return arr\n",
        "  else:\n",
        "    clear_output(wait=True)\n",
        "    skipped = skipped + skip_count\n",
        "    print(f'Computed row {row_iter} / {df_rows}.\\nSkipped {skipped} citations, applied cosine simmilarity to {applied} citations so far ... ')\n",
        "    return []\n",
        "\n",
        "def get_cosine_simmilarity(ref, arr):\n",
        "  global all_refs\n",
        "  count = 1\n",
        "  cosines=[]\n",
        "  for u in arr:\n",
        "    temp_json = {}\n",
        "    temp_json[\"citation\"] = u.rstrip()\n",
        "    temp_json[\"cosine\"] = cosine_sim( ref, u )\n",
        "    temp_json[\"id\"] = all_refs.index(u)\n",
        "    cosines.append(temp_json) # could average them when decide which to include in the citation network ...\n",
        "  return cosines\n",
        "\n",
        "def get_refs(row):\n",
        "  global all_refs\n",
        "  ref_json = decode(row[\"reference_array\"])\n",
        "  for ref in ref_json:\n",
        "    if ( ref not in all_refs ):\n",
        "      all_refs.append(ref)\n",
        "  # print(1+\"1\")\n",
        "  all_refs.append(row[\"citation\"])\n",
        "  all_refs = sorted(all_refs, key=len)\n",
        "\n",
        "total_cosine = 0\n",
        "def get_ref_freq(row):\n",
        "  global all_refs\n",
        "  global row_iter\n",
        "  global cit_iter\n",
        "  global total_cosine\n",
        "\n",
        "  is_positive = False\n",
        "  if ( str(row[\"Status\"]) == \"1\" ):\n",
        "    is_positive = True\n",
        "\n",
        "  row_iter = row_iter + 1\n",
        "  ref_json = decode(row[\"reference_array\"])\n",
        "  freq = []\n",
        "  cit_iter = 0\n",
        "  for ref in ref_json:\n",
        "    cit_iter = cit_iter + 1\n",
        "\n",
        "    arr = check_if_viable_for_cosine_sim(ref, is_positive)\n",
        "    if ( arr != [] ):\n",
        "      total_cosine = total_cosine + 1\n",
        "      # print(1+\"1\")\n",
        "      # freq.append( '{ citation:\"' + ref + '\", freq:' + str(all_refs.count(ref)) + \", id:\" + str(all_refs_unique.index(ref)) + \"}\")\n",
        "      temp_json = {}\n",
        "      temp_json[\"citation\"] = ref.rstrip()\n",
        "      # temp_json[\"freq\"] = str(all_refs.count(ref))\n",
        "      temp_json[\"cosine\"] = get_cosine_simmilarity(ref, arr)\n",
        "      temp_json[\"id\"] = all_refs.index(ref)\n",
        "      freq.append( temp_json )\n",
        "  return freq\n",
        "\n",
        "start = time.time()\n",
        "for i in range(10, len(cit_dfs)):\n",
        "# for i in range(0, 1):\n",
        "  # if ( i == 6 ):\n",
        "  #   continue\n",
        "  all_refs = []\n",
        "  skipped = 0\n",
        "  applied = 0\n",
        "  df_rows = len(cit_dfs[i])\n",
        "  row_iter = 0\n",
        "  cit_iter = 0\n",
        "  df_cit_iter = 0\n",
        "  average_citation_count = 0\n",
        "  print(\"Getting refs for current citation df ...\", end=\"\")\n",
        "  cit_dfs[i] = cit_dfs[i].sort_values(\"Status\")\n",
        "  cit_dfs[i].apply( get_refs, axis=1 )\n",
        "  print(\" - DONE\")\n",
        "  cit_dfs[i][\"reference_array\"] = cit_dfs[i].apply( get_ref_freq, axis=1 )\n",
        "\n",
        "  cit_dfs[i].to_csv(\"/content/drive/MyDrive/Citation_dataframes/cit_dfs_\" + str(i) + \"_\" + filenames[i], encoding='utf-8', index=False)\n",
        "\n",
        "end = time.time()\n",
        "length = end - start\n",
        "\n",
        "print(length)\n",
        "print(length/60)\n",
        "print(length%60)\n",
        "# cit_dfs[0]\n",
        "# ok\n",
        "# SHOULD DO SOMETHING TO ENSURE THAT FOR THE POSITIVE ARTICLES ALL CITATIONS ARE CONSIDERED ... THAT THEY DONT HAVE AN EMPTY CITATION LISTN AFTER THIS ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuKjCBX95mAW",
        "outputId": "19956172-c007-4188-d4fe-db4525652633"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "cit_dfs = []\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "from pathlib import Path\n",
        "import os\n",
        "import glob\n",
        "csv_df = pd.DataFrame(columns=[])\n",
        "for file in glob.glob(\"/content/drive/MyDrive/Citation_dataframes/*.csv\"):\n",
        "  filename = os.path.basename(file)\n",
        "  temp_df = pd.read_csv(file, index_col=0)\n",
        "  cit_dfs.append(temp_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLexAbwr6Vq2"
      },
      "outputs": [],
      "source": [
        "# this is just to ensure the validity of the jsons inside \"reference_array\"\n",
        "\n",
        "def get_json(row):\n",
        "  res_json = decode(row[\"reference_array\"])\n",
        "  # print( res_json )\n",
        "\n",
        "for i in range(0, len(cit_dfs)):\n",
        "  cit_dfs[i].apply( get_json, axis=1 )\n",
        "  # cit_dfs[i] = cit_dfs[i].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joOcC6482vmh",
        "outputId": "9a18d250-60f1-475a-b437-cdd0c04f34f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "662"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total_cosine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmRjrcKUAA-j",
        "outputId": "353785c2-3856-4b35-a0d0-f3cd5c34866b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "round(23/18 - 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ap9C0b1ak3o8",
        "outputId": "b8088457-3c8b-473d-c722-7af0f6d74984"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['finished_new_prompt_CD012768_hard.csv',\n",
              " 'ada_embed_CD012768.csv',\n",
              " 'finished_new_prompt_CD012768_soft.csv',\n",
              " 'finished_new_prompt_CD012768.csv',\n",
              " 'ada_embed_CD008874.csv',\n",
              " 'finished_new_prompt_CD008874.csv',\n",
              " 'finished_new_prompt_CD008874_soft.csv',\n",
              " 'ada_embed_CD009044.csv',\n",
              " 'finished_new_prompt_CD009044.csv',\n",
              " 'finished_new_prompt_CD009044_hard.csv',\n",
              " 'finished_new_prompt_CD009044_soft.csv',\n",
              " 'ada_embed_CD011686.csv',\n",
              " 'finished_new_prompt_CD011686.csv',\n",
              " 'finished_new_prompt_CD011686_hard.csv',\n",
              " 'finished_new_prompt_CD011686_soft.csv',\n",
              " 'ada_embed_CD012080.csv',\n",
              " 'finished_new_prompt_CD012080.csv',\n",
              " 'finished_new_prompt_CD012080_hard.csv',\n",
              " 'finished_new_prompt_CD012080_soft.csv',\n",
              " 'finished_new_prompt_CD012233_soft.csv',\n",
              " 'finished_new_prompt_CD012233.csv',\n",
              " 'ada_embed_CD012233.csv',\n",
              " 'finished_new_prompt_CD012233_hard.csv',\n",
              " 'ada_embed_CD012567.csv',\n",
              " 'finished_new_prompt_CD012567.csv',\n",
              " 'finished_new_prompt_CD012567_hard.csv',\n",
              " 'finished_new_prompt_CD012567_soft.csv',\n",
              " 'ada_embed_CD012669.csv',\n",
              " 'finished_new_prompt_CD012669.csv',\n",
              " 'finished_new_prompt_CD012669_hard.csv',\n",
              " 'finished_new_prompt_CD012669_soft.csv']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filenames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "oJqS3tZU-hNx",
        "outputId": "43ce5c59-eac2-466c-db9c-e0c9480ab4cc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reference_array</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ],
            "text/plain": [
              "count     106\n",
              "unique     67\n",
              "top        []\n",
              "freq       40\n",
              "Name: reference_array, dtype: object"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cit_dfs[0][\"reference_array\"].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZ9SvX-U61oJ"
      },
      "outputs": [],
      "source": [
        "cit_dfs[0].to_csv(\"/content/drive/MyDrive/cit_dfs0_just_cosine_simmilarity_1.csv\", encoding='utf-8', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuKHU8yW_5is",
        "outputId": "ac9063b9-3b1b-43e2-d2b8-d02dcaf4a388"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['7', '5', '2', '6']"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "LZBwgSSxBewA",
        "outputId": "27b8851e-75f6-456e-c695-4698405e5abd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1539\n",
            "The American review of respiratory disease BE Jones 148 1292 1993 10.1164/ajrccm/148.5.1292 Relationship of the manifestations of tuberculosis to CD4 cell counts in patients with human immunodeficiency virus infection.\n",
            "313\n",
            "NOT 1\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-636ac2863a59>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mcit_dfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mprint_refs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10372\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10373\u001b[0m         )\n\u001b[0;32m> 10374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10376\u001b[0m     def map(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_numba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-69-636ac2863a59>\u001b[0m in \u001b[0;36mprint_refs\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"freq\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"1\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# they are ALL 1 ... so, I would want to make a NLP-type comparison of them, to have a frequency that is NOT 1 ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"NOT 1\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
          ]
        }
      ],
      "source": [
        "cit_dfs[0] = cit_dfs[0].astype(str)\n",
        "\n",
        "def print_refs(row):\n",
        "  global all_refs\n",
        "  ref_json = decode(row[\"reference_array\"])\n",
        "  for ref in ref_json:\n",
        "    # print(ref)\n",
        "    # ref = decode(ref)\n",
        "    print(ref[\"id\"])\n",
        "    print(ref[\"citation\"])\n",
        "    print(ref[\"freq\"])\n",
        "    if ( str(ref[\"freq\"]) != \"1\" ): # they are ALL 1 ... so, I would want to make a NLP-type comparison of them, to have a frequency that is NOT 1 ...\n",
        "      print( \"NOT 1\" )\n",
        "      print(1 + \"1\")\n",
        "    print(\"\\n\\n\")\n",
        "\n",
        "cit_dfs[0].apply( print_refs, axis=1 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-1IswUflGh1"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "data = {\"pmid\": [], \"citation\": []}\n",
        "citation_df = pd.DataFrame(data)\n",
        "\n",
        "def parse_citations(row):\n",
        "  references_json = json.loads(row[\"references\"])\n",
        "  for ref in references_json:\n",
        "    if ( \"pubmed\" in ref[\"article_ids\"] ):\n",
        "      citation_df.loc[len(citation_df)] = [row[\"pmid\"], \"PMID-\"+str(ref[\"article_ids\"][\"pubmed\"])]\n",
        "      continue\n",
        "    if ( \"pmc\" in ref[\"article_ids\"] ):\n",
        "      citation_df.loc[len(citation_df)] = [row[\"pmid\"], \"PMC-\"+str(ref[\"article_ids\"][\"pmc\"])]\n",
        "      continue\n",
        "\n",
        "    citation_df.loc[len(citation_df)] = [row[\"pmid\"], \"TITLE-\"+str(ref[\"citation\"])]\n",
        "    continue\n",
        "\n",
        "citations.apply( parse_citations, axis=1 )\n",
        "citation_df = citation_df.astype(str)\n",
        "citation_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FhRiiUgfAZT"
      },
      "outputs": [],
      "source": [
        "citation_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7qvuuWqcp_J"
      },
      "outputs": [],
      "source": [
        "# Citation network with ALL citations ...\n",
        "\n",
        "citation_network = nx.from_pandas_edgelist(citation_df, \"pmid\", \"citation\")\n",
        "# nx.draw_spring(citation_network) # draw_planar / draw / draw_spring - those are the best visualisation functions ...\n",
        "print( \"Number of connected components: \" + str( nx.number_connected_components(citation_network) ) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cWJNeFrxQ8G"
      },
      "outputs": [],
      "source": [
        "# CODE FOR MAKING A CITATION NETWORK FOR EACH ARTICLE INDIVIDUALLY\n",
        "\n",
        "# initial_article_pmids = list(citation_df['pmid'].unique())\n",
        "\n",
        "# # article_dfs=[]\n",
        "# for initial_article_pmid in initial_article_pmids:\n",
        "#   article_df = citation_df[citation_df[\"pmid\"]==initial_article_pmid]\n",
        "\n",
        "#   citation_network = nx.from_pandas_edgelist(article_df, \"pmid\", \"citation\")\n",
        "#   nx.draw_spring(citation_network) # draw_planar / draw / draw_spring - those are the best visualisation functions ...\n",
        "#   print( \"Number of connected components: \" + str( nx.number_connected_components(citation_network) ) )\n",
        "\n",
        "#   # article_dfs.append( article_df )\n",
        "\n",
        "# article_df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}